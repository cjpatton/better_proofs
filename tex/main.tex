\documentclass{article}
\usepackage{amsmath, amsthm}
\usepackage{listings}
\usepackage{listings-rust}
\usepackage[margin=1in]{geometry}
\usepackage{sourcecodepro}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage[svgnames]{xcolor}

\lstset{
  language=rust,
  style=boxed,
}

% Colors

\definecolor{darkgreen}{RGB}{30,97,0}

% Theorems

\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}

% Macros

\newcommand{\authnote}[3]{%
  {
    \color{#1}%
    \textbf{[#2:~}%
    {%
      #3%
    }%
    \textbf{]}%
  }%
}
\newcommand{\cp}[1]{\authnote{darkgreen}{Chris P.}{#1}}

\newcommand{\bad}{\mathit{bad}}
\newcommand{\Adv}[1]{\textrm{\textup{Adv}}^{\textup{#1}}}
\newcommand{\Prob}[1]{\Pr\hspace{-1pt}\big[\,#1\,\big]}
\newcommand{\code}[1]{\textrm{\textup{\lstinline{#1}}}}

\title{How to write proofs for cryptographic protocols at IETF}
\author{Christopher Patton ({\texttt{\small chrispatton+ietf@gmail.com}})}

\begin{document}

\maketitle

\begin{abstract}

  For many protocols at IETF, security rests on ``pen-and-paper'' proofs that
  are difficult for humans to verify.
  %
  If the demand for provable security outpaces the capacity of human reviewers,
  then we run the risk of missing bugs that may belie attacks.
  %
  One way to prevent this is to mechanize portions of the review process.
  %
  This essay sketches a vision for writing security proofs in which there is a
  clear division of labor between subject matter experts and experts in formal
  methods.
  %
  This, we hope, will lead to more productive interactions across disciplines
  and to more of our proofs being fully vetted.

\end{abstract}

\section{Introduction}

This essay accompanies a talk for
\href{https://datatracker.ietf.org/group/ufmrg/about/}{UFMRG} at IETF 120.
%
It is not a traditional research paper and is based largely on my own
observations. Its main purpose is to gather feedback.


\paragraph{Code-based game-playing proofs~\cite{BR06}.}
%
Game playing is a well-known paradigm for establishing computational security
properties of cryptographic protocols.
%
In this paradigm, the security goal and execution environment are modeled as a
\emph{game} played by the attacker. A \emph{proof} of security in this model
relates the attacker's advantage in winning the game to the difficulty of one
or more presumed hard problems, like breaking AES or solving discrete
logarithms on the elliptic curve used by the protocol.

Games are often expressed in \emph{code} rather than natural language, making
them amendable to the following proof strategy.
%
The proof consists of a sequence of games (sometimes called \emph{hybrids})
beginning with the game that defines security.
%
Each game is obtained by rewriting the code of the previous one until, in the
final game, the attacker interacts with some idealized system that it has no
hope of breaking.

The security proof establishes that, for each pair of neighboring games, the
probability of an attacker in distinguishing between them is negligible.
%
This is established in various ways:
%
sometimes a \emph{rewrite} (also called a \emph{hop} or \emph{transition})
results in a game that is semantically equivalent, in which case no attacker
can distinguish them;
%
others rewrites result in distinguishable events that occur only with small
probability, such as a collision in the range of a random oracle;
%
still others are bounded computationally, by reducing a distinguisher to
breaking some underlying assumption.

In recent years, security analyses of this sort have played an increasingly
central role in the design and analysis of protocols specified at IETF. We have
seen working groups move from \emph{reacting} to knew attacks to
\emph{proactively} seeking security analysis during the design
phase~\cite{KT16}.
%
In fact, we have even seen this process formalized in the TLS working
group~\cite{tls13-formal-analysis-triage-panel}.
%
While steps like these go a long way towards preventing attacks, the provable
security methodology has some well-known limitations~\cite{Ber19}.
%
We consider one of them here.

\paragraph{Our crisis of rigor.}
%
In their seminal paper on the subject from Eurocrypt 2006~\cite{BR06}, Bellare
and Rogaway assessed that many security proofs of the era were ``essentially
unverifiable''. They feared the discipline would eventually reach a ``crisis of
rigor'' in which proofs were believed without being fully vetted, allowing
errors in these proofs to go unnoticed. And some of these errors may belie
attacks.
%
%In our experience, this fear has, at least in part, come to fruition.

Today, carefully checking security proofs remains a significant challenge.
There are at least three exacerbating factors:
%
\begin{enumerate}

  \item Proofs are most often written in some \emph{pseudocode} language
    intended for human readers. These are often called \emph{pen-and-paper}
    proofs.
    %
    There is no ``standard'' pseudocode in use today, and the grammar and
    semantics of these languages are as varied as the people that use them.
    %
    Not only does this make mechanized verification nearly impossible, it also
    makes life difficult for human reviewers, many of whom may have a stack of
    10 papers or more to review, each with its own unique and possibly
    incompatible semantics.

  \item Protocols of interest to IETFers are becoming more complex.
    %
    First, we are seeing our community do more with cryptography, often going
    beyond well-studied goals like key exchange, authentication, and
    encryption.
    %
    Second, as attackers get more sophisticated, so must our security definitions
    capture the real execution environment in greater fidelity.
    %
    Proofs are getting \emph{longer} as a result, putting pressure on authors
    to merely ``sketch'' the proof in order to meet the page limit for the
    conference submission. Or they simply punt the proof to the paper's
    appendix, which program committee members are typically not required to
    review at all.

  \item Mechanization of security proofs can help reduce burden on human
    reviewers.
    %
    Several tools exist for this, including
    \href{https://bblanche.gitlabpages.inria.fr/CryptoVerif/}{CryptoVerif},
    \href{https://github.com/EasyCrypt/easycrypt}{EasyCrypt}, and
    \href{https://github.com/SSProve/ssprove}{SSProve}, but these tools remain
    somewhat inaccessible to many folks writing pen-and-paper proofs today.
    %
    There are several reasons for this.
    %
    First and foremost, cajoling the theorem prover into generating a proof is
    in general a manual process that requires some degree of domain expertise
    in the theory that underlies the proof assistant.
    %
    Beyond that, the requirement to learn a new, somewhat esoteric programming
    language, tools that are specialized to specific applications or use cases,
    and the maturity of the software itself can all be barriers to entry.

\end{enumerate}
%
These factors put our community on a trajectory that, in my view, is not be
sustainable long term.
%
I believe we must find ways to reduce the cost of checking security proofs so
that the capacity of reviewers continues to meet the demands of those
developing cryptographic protocols in practice.

%Because each of these issues is socially constructed~\cite{Rog09} to some
%degree, we should not expect any one of them to be resolved by technical means
%alone.
%
%However, it is our belief that the current trajectory of practice-oriented
%provable security cannot be sustained indefinitely.

\paragraph{Proposal.}
%
This essay puts forward a vision for writing security proofs for cryptographic
protocols developed at IETF.
%
Proofs ought to meet to basic requirements.
%
First, proofs must be immediately amendable to mechanized verification so that
human verifiers need not check the full proof.
%
Second, generating proofs must not require significantly more effort or
expertise than pen-and-paper so that human provers are not tempted to write a
proof sketch only.

The key idea is simple: proofs should be written in a programming language
that:
%
\begin{enumerate}
  \item is already in wide use at IETF;

  \item is high-level enough to be suitable as a specification language. That
    is is, the protocol can be understood without expertise in the language;
    and

  \item is the target language for production software so that the
    specification itself can be more easily integrated into these systems.
\end{enumerate}
%
This is not a particularly novel idea, yet it is not an idea that has taken
root among mast practitioners of provable security.
%
Part of the problem is the lack of a consensus language with suitable tools for
formal methods. As I will try to illustrate here, we may be on the cusp of a
solution.

The potential benefit of writing game-playing proofs in an actual code rather
than pseudocode is that it creates a \emph{separation of concerns} that results
in higher quality and more efficient collaborations across disciplines.
%
On one end of the assembly line, the \emph{subject matter expert} specifies the
security game and protocol and generates the proof, consisting of the game
rewrites and reductions. Ideally, this requires no knowledge of formal methods,
only the specification language.
%
On the other end of the assembly line, the \emph{formal methods expert}
verifies correctness of each of the rewrites. Ideally, this amounts to checking
equivalence of programs written in the specification language and requires no
knowledge about the details of the application.

Other benefits to this approach:

\begin{itemize}
  \item Those of us IETFers who write security proofs as well as software will
    discover some surprising benefits of this approach.
    %
    For example, imagine you have written a proof and pseudocode and find you
    need to go back and tweak the definition: the process of propagating that
    tweak through the proof is both time-intensive and error-prone. Having a
    compiler with a type checker and a set of high-quality unit tests can make
    this much more sane.

  \item Cryptographers spend a large amount of energy working on definitions.
    Much of this time is spent probing for ``trivial'' distinguishers or
    winning conditions that would suggest the attacker is too powerful or not
    captured in the right way.
    %
    Writing such definitions in code might make it possible to formalize such
    conditions symbolically in tools like
    \href{https://tamarin-prover.com/}{Tamarin} or
    \href{https://bblanche.gitlabpages.inria.fr/proverif/}{ProVerif}.
\end{itemize}

\paragraph{Outline.}
%
In this essay study a few elementary examples of security proofs from the
cryptographic literature, transcribing them into a high-level programming
language.
%
These examples illustrate the kind of work carried out by the \emph{subject
matter expert}; the task of the \emph{formal methods expert} is to prove each
claim (written as \textbf{Claim}) in the body of the proof.
%
Section~\ref{sec/hybrid} recalls the simple hybrid, public-key encryption
scheme from Mike Rosulek's ``Joy of Cryptography''`~\cite{joy} and proves it

These examples illustrate three common game rewrites:
%
\emph{equivalent-rewrite}, in which the new code is semantically equivalent
(useful for setting up the next step in the proof);
%
\emph{equivalent-by-reduction}, in which a distinguisher is reduced to a
distinguisher of a simpler game; and
%
\emph{equivalent-until-bad}, in which the new game is equivalent up to some
distinguishing, ``bad'' event~\cite{BR06}.


\paragraph{What about UC?}
%
While we focus on game-playing proofs, the same idea can be applied to what is
often called the \emph{simulation paradigm}. Here security is defined relative
to some \emph{ideal functionality}, and we say the protocol \emph{realizes}
that ideal functionality if, for every attacker, there exists a simulator such
that the adversary's interaction with the real system is indistinguishable from
the simulator's interaction with the ideal functionality.
%
There is no fundamental difference between simulation- and game-based
definitions that makes mechanization of proofs in one paradigm harder than the
other.
%
However, the details of popular simulation frameworks, like UC
framework~\cite{Can01}, can be rather involved, making mechanization more
difficult~\cite{CSV19}.
%
Games are an attractive target merely because the details of the model are
explicit and often simpler.


\paragraph{Caveat.}
%
You will find this proposal is somewhat opinionated: it is grounded in
extensive experience writing pen-and-paper proofs (sometimes with bugs!), but
no practical experience with mechanized verification or other formal methods.
%
It may be that I'm massively underestimating how much work is being delegated
to formal methods.


\section{Notation}

All algorithms, including games and adversaries, are Rust
(\url{https://www.rust-lang.org/}) programs without asynchronous semantics
(i.e., with the $\code{async}$ and $\code{await}$ key words
removed).\footnote{Asynchronous Rust is excluded because it is not needed to
formalize execution of games.}
%
By convention, an adversary's runtime includes the time it takes to initialize
its game and evaluate its oracle queries.
%
Let $\code{block}$ be a Rust code block whose last statement is an expression
that evaluates to $\code{bool}$.
%
We denote by $\Prob{\code{block}}$ the probability that execution of
$\code{block}$ halts (without panicking) and outputs $\code{true}$.
%
We model
\href{https://rust-random.github.io/rand/rand/fn.thread_rng.html}{$\code{thread_rng()}$}
from the
\href{https://rust-random.github.io/rand/rand/index.html}{$\code{rand}$} crate
as an ideal source of uniform random coins.

\paragraph{Why Rust?}
%
Rust easily meets two of our criteria: it is widely used at IETF and in
production software systems.
%
Whether it is suitable as a specification language is debatable; I will try to
make the case that it is, by conveying to the reader what elements of Rust are
important to understanding definitions herein.

Another important reason for choosing Rust is that it is the specification
language of the HAX toolchain (\url{https://cryspen.com/hax/}).
%
HAX is used to transcribe Rust into one of many \emph{backend} languages, such
as F* and Coq, where existing tools can be applied for various purposes.
%
HAX was not designed with this particular use case in mind, and based on our
initial experiments with, it appears to not yet be complete enough to work.


\begin{figure}[t]
\begin{lstlisting}
/// Syntax.
pub trait PubEnc {
    type PublicKey;
    type SecretKey;
    type Plaintext;
    type Ciphertext;
    fn key_gen(&self) -> (Self::PublicKey, Self::SecretKey);
    fn encrypt(&self, pk: &Self::PublicKey, m: &Self::Plaintext) -> Self::Ciphertext;
    fn decrypt(&self, sk: &Self::SecretKey, c: &Self::Ciphertext) -> Option<Self::Plaintext>;
}

/// Security.
pub struct PubCpa<E: PubEnc> {
    enc: E,
    pk: E::PublicKey,
    right: bool,
}
impl<E: PubEnc> PubCpa<E> {
    pub fn init(enc: E, right: bool) -> Self {
        let (pk, _sk) = e.key_gen();
        Self { enc, pk, right }
    }
}
impl<E: PubEnc> GetPublicKey for PubCpa<E> {
    type PublicKey = E::PublicKey;
    fn get_pk(&self) -> &E::PublicKey {
        &self.pk
    }
}
impl<E: SymEnc> LeftOrRight for PubCpa<E> {
    type Plaintext = E::Plaintext;
    type Ciphertext = E::Ciphertext;
    fn left_or_right(&self, m_left: &E::Plaintext, m_right: &E::Plaintext) -> E::Ciphertext {
        if self.right {
            self.enc.encrypt(&self.k, m_right)
        } else {
            self.enc.encrypt(&self.k, m_left)
        }
    }
}
\end{lstlisting}
  \caption{Syntax of PKE and game \lstinline{PubCpa}
  for defining security under chosen plaintext attack (CPA).}
  \label{fig/pubenc/security}
  \label{fig/pubenc/syntax}
\end{figure}


\section{Example: Hybrid Encryption}\label{sec/hybrid}

We first consider the hybrid public-key encryption (PKE) scheme of
\cite[Chapter~15]{joy}.
%
The proof demonstrates two types of game transitions: \emph{equivalent-rewrite}
and \emph{equivalent-by-reduction}.


\subsection{Syntax}

A PKE scheme implements the $\code{PubEnc}$ trait listed in
Figure~\ref{fig/pubenc/syntax}.
%
(A \emph{trait} is similar to an interface or abstract base class in other
languages that defines an API but not an implementation of the API.)
%
Let $\code{enc: E}$ implement $\code{PubEnc}$.
%
(That is, $\code{enc}$ is a PKE scheme because its type, denoted $\code{E}$
implements the $\code{PubEnc}$ trait. See Figure~\ref{fig/hybrid}, line~5.)
%
We say $\code{enc}$ is \emph{correct} if for all $\code{m} \in
\code{E::Plaintext}$ it holds that
%
\[
  \Prob{
    \code{let (pk, sk) = enc.key_gen();
    enc.decrypt(sk, enc.encrypt(pk, m)) == Some(m)}
  } = 1 \,.
\]


\subsection{Security}

Security under chosen plaintext attack (CPA) is defined by the $\code{PubCpa}$
game in Figure~\ref{fig/pubenc/security}.
%
It captures a left-or-right notion of indistinguishability by giving the
attacker an oracle \hyperref[sec/traits]{$\code{LeftOrRight}$} that encrypts
one of two messages chosen by the attacker and returns the ciphertext.
%
(Each trait implemented by the game defines an oracle that the attacker has
access to. One is $\code{LeftOrRight}$; the other is
\hyperref[sec/traits]{$\code{GetPublicKey}$}, which grants access to the
encryption key.)
%
Which message is encrypted is controlled by a boolean $\code{right}$ used to
initialize the game (line 19).

\begin{definition}[{\cite[Definition 15.1]{joy}}]
  Let~$A$ implement \hyperref[sec/traits]{$\code{Distinguisher}$}.
  %
  Let~$\code{enc}$ implement \hyperref[fig/pubenc/syntax]{$\code{PubEnc}$}.
  %
  Define the advantage of attacker~$A$ in breaking the security of
  $\code{enc}$ under CPA as
  %
  \[
    \Adv{cpa}_{\code{enc}}(A) =
      \Prob{A\code{.play(PubCpa::init(enc, false))}} -
      \Prob{A\code{.play(PubCpa::init(enc, true))}} \,,
  \]
  %
  where $\code{PubCpa}$ is as defined in Figure~\ref{fig/pubenc/security}.
  %
  Informally, we say $\code{enc}$ is secure under CPA if every efficient
  attacker has small advantage.
\end{definition}

\begin{remark}
  This definition implicitly requires length hiding, since there is no
  requirement that the challenge plaintext $\code{m_left}$ and $\code{m_right}$
  have the same length. For most PKE schemes, the length of the ciphertext is a
  function of the length of the plaintext.
\end{remark}


\begin{figure}[t]
\begin{lstlisting}
pub struct Hybrid<P, S> {
    pub pub_enc: P,
    pub sym_enc: S,
}
impl<P, S> PubEnc for Hybrid<P, S>
where
    S: SymEnc,
    P: PubEnc<Plaintext = S::Key>,
    Standard: Distribution<S::Key>,
{
    type PublicKey = P::PublicKey;
    type SecretKey = P::SecretKey;
    type Plaintext = S::Plaintext;
    type Ciphertext = (P::Ciphertext, S::Ciphertext);
    fn key_gen(&self) -> (P::PublicKey, P::SecretKey) {
        self.pub_enc.key_gen()
    }
    fn encrypt(&self, pk: &P::PublicKey, m: &S::Plaintext) -> (P::Ciphertext, S::Ciphertext) {
        let tk = thread_rng().gen(); // "temporary key"
        let c_pub = self.pub_enc.encrypt(pk, &tk);
        let c_sym = self.sym_enc.encrypt(&tk, m);
        (c_pub, c_sym)
    }
    fn decrypt(
        &self,
        sk: &Self::SecretKey,
        (c_pub, c_sym): &(P::Ciphertext, S::Ciphertext),
    ) -> Option<Self::Plaintext> {
        let tk = self.pub_enc.decrypt(sk, c_pub)?;
        let m = self.sym_enc.decrypt(&tk, c_sym)?;
        Some(m)
    }
}
\end{lstlisting}
  \caption{Hybrid PKE scheme of \cite[Construction 15.8]{joy}.}
  \label{fig/hybrid}
\end{figure}


\subsection{Construction}

In practice, PKE schemes are most often constructed by combining symmetric
encryption with a mechanism for encapsulating the encryption key to the
intended recipient~\cite{rfc9180} (that is, the holder of the secret key
corresponding to the public encapsulation key).
%
By way of gentle introduction to this paradigm, Mike Rosulek gives a
construction of CPA-secure, hybrid encryption in ``The Joy of
Cryptography''~\cite{joy}.
%
We recall this construction in Figure~\ref{fig/hybrid}.

This construction transforms a symmetric encryption scheme $\code{sym_enc: S}$
into a PKE scheme.
%
The syntax and security of symmetric encryption are defined similarly to PKE,
except there is no public key; we defer the formal definition to
Appendix~\ref{sec/symenc}.
%
The transformation involves a PKE scheme $\code{pub_enc: E}$ with a small
plaintext space. In particular, we require that plaintext space of
$\code{pub_enc}$ is the same as the key space for $\code{sym_enc}$. This is
formalized by the trait bound $\code{E: PubEnc<Plaintext = S::Key>}$ (see line
8).

To encrypt a plaintext, we choose a ``temporary key'' $\code{tk}$ uniform
randomly from the key space of $\code{sym_enc}$.
%
We then encrypt $\code{tk}$ using the PKE scheme $\code{pub_enc}$.
%
Finally, we encrypt the plaintext under $\code{tk}$ and output both
ciphertexts.

\begin{theorem}\label{thm/hybrid}
  Suppose that $\code{pub_enc}$ and $\code{sym_enc}$ satisfy the constraints of
  Figure~\ref{fig/hybrid} and let $\code{hybrid} = \code{Hybrid\{
    pub_enc, sym_enc \}}$.
  %
  Then for every $\code{hybrid}$-attacker $A$ there exist a
  $\code{sym_enc}$-attacker $B$ and a $\code{pub_enc}$-attacker $C$ with
  the same runtime as $A$ for which
  %
  \[
    \Adv{cpa}_\code{hybrid}(A) \leq
      \Adv{cpa}_\code{sym_enc}(B) +
      2\cdot\Adv{cpa}_\code{pub_enc}(C) \,.
  \]
\end{theorem}

\begin{proof}
  \input{hybrid-proof}
\end{proof}


\section{Example: The PRP/PRF Switching Lemma}\label{sec/switching}

In this section we fix the PRP/PRF switching lemma~\cite{BR06}, which states
that a good pseudorandom permutation (PRP) is a good pseudorandom function
(PRF) up to birthday attacks.
%
The proof demonstrates the \emph{equivalent-until-bad} transition.

\begin{figure}[t]
\begin{lstlisting}
/// Syntax.
pub trait Func {
    type Key;
    type Domain: ?Sized;
    type Range;
    fn eval(&self, k: &Self::Key, x: &Self::Domain) -> Self::Range;
}

/// Real game for defining PRP and PRF security.
pub struct Real<F: Func> {
    f: F,
    k: F::Key,
}
impl<F: Func> Real<F>
where
    Standard: Distribution<F::Key>,
{
    pub fn with(f: F) -> Self {
        let k = thread_rng().gen();
        Self { f, k }
    }
}
impl<F: Func> Eval<F> for Real<F> {
    fn eval(&mut self, x: &F::Domain) -> F::Range {
        self.f.eval(&self.k, x)
    }
}
\end{lstlisting}
  \caption{Syntax and real security game for PRPs and PRFs. The ideal games are
  listed in Appendix~\ref{sec/func/ideal}.}
  \label{fig/func/syntax}
  \label{fig/func/real}
\end{figure}


Syntactically, both a PRP and PRF implement the $\code{Eval}$ trait listed in
Figure~\ref{fig/func/syntax}.\footnote{A PRP also implements the inverse of
$\code{Eval::eval()}$. We do not list this syntax because it is not needed
here.}
%
For example, the AES-128 blockipher would set $\code{Key}$, $\code{Domain}$,
and $\code{Range}$ to $\code{[u8; 16]}$.
%
Security is defined by the $\code{Real}$ game in Figure~\ref{fig/func/real},
which gives the attacker an oracle for the function with a randomly sampled
key. In the ideal PRP and PRF games, the oracle lazy evaluates, respectively, a
random permutation and a random function.
%
The ideal games, denoted $\code{RandPerm}$ and $\code{RandFunc}$, are listed
for completeness in Appendix~\ref{sec/func/ideal}.

Let $\code{f: F}$ implement \hyperref[fig/func/syntax]{$\code{Func}$} and
let~$A$ implement \hyperref[sec/traits]{$\code{Distinguisher}$} for
\hyperref[sec/traits]{$\code{Eval<F>}$}.

\begin{definition}[PRP]
  Define the advantage of~$A$ in distinguishing $\code{f}$ from a random
  permutation as
  %
  \[
    \Adv{prp}_\code{f}(A) =
      \Prob{A\code{.play(Real::with(f))}} -
      \Prob{A\code{.play(RandPerm::default())}} \,.
  \]
  %
  (The $\code{default()}$ method is provided by the
  \href{https://doc.rust-lang.org/std/default/trait.Default.html}{$\code{Default}$}
  trait, which the \hyperref[sec/traits]{$\code{RandPerm}$} trait derives automatically.
  The hash map and hash set are initially empty.)
  %
  Informally, we say $\code{f}$ is a PRP if every efficient attacker gets small
  advantage.
\end{definition}

\begin{definition}[PRF]
  Define the advantage of~$A$ in distinguishing $\code{f}$ from a random
  function as
  %
  \[
    \Adv{prf}_\code{f}(A) =
      \Prob{A\code{.play(Real::with(f))}} -
      \Prob{A\code{.play(RandFunc::default())}} \,.
  \]
  %
  Informally, we say $\code{f}$ is a PRF if every efficient attacker gets small
  advantage.
\end{definition}

\begin{lemma}[{\cite[Lemma 1]{BR06}}]
  Suppose $A$ makes at most $q$ queries to its oracle. Then
  %
  \[
    \Adv{prp}_\code{f}(A) \leq
      \Adv{prf}_\code{f}(A) +
      \frac{q(q-1)}{2|\code{F::Range}|} \,.
  \]
\end{lemma}
\begin{proof}
  \input{switching-proof}
\end{proof}


\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{references}


\appendix


\section{Deferred Definitions}

\subsection{Symmetric Encryption}
\label{sec/symenc}

A symmetric encryption scheme implements the $\code{SymEnc}$ trait listed in
Figure~\ref{fig/symenc/syntax}.
%
Let $\code{enc: E}$ implement $\code{SymEnc}$.
%
We say $\code{enc}$ is \emph{correct} if for all $\code{m} \in
\code{E::Plaintext}$ it holds that
%
\[
  \Prob{
    \code{let k = e.key_gen();
    enc.decrypt(k, enc.encrypt(k, m)) == Some(m)}
  } = 1 \,.
\]
%
Security under chosen plaintext attack (CPA) is defined by the $\code{Cpa}$
game in Figure~\ref{fig/symenc/security}.

\begin{definition}[{\cite[Definition 7.1]{joy}}]
  Let $A$ implement \hyperref[sec/traits]{$\code{Distinguisher}$}.
  %
  Let~$\code{enc}$ implement \hyperref[fig/symenc/syntax]{$\code{SymEnc}$}.
  %
  Define the advantage of~$A$ in breaking the security of $\code{enc}$ under CPA
  as
  %
  \[
    \Adv{cpa}_{\code{enc}}(A) =
      \Prob{A\code{.play(Cpa::init(enc, false))}} -
      \Prob{A\code{.play(Cpa::init(enc, true))}} \,.
  \]
  %
  Informally, we say $\code{enc}$ is secure under CPA if every efficient adversary
  has small advantage.
\end{definition}


\subsection{Ideal games for defining PRPs and PRFs}
\label{sec/func/ideal}

\begin{lstlisting}
/// Ideal game for defining PRP security.
#[derive(Default)]
pub struct RandPerm<F: Func>
where
    F::Domain: Sized,
{
    table: HashMap<F::Domain, F::Range>,
    range: HashSet<F::Range>,
}
impl<F: Func> Eval<F> for RandPerm<F>
where
    Standard: Distribution<F::Range>,
    F::Domain: Clone + std::hash::Hash + Eq,
    F::Range: Clone + std::hash::Hash + Eq,
{
    fn eval(&mut self, x: &F::Domain) -> F::Range {
        let mut rng = thread_rng();
        self.table
            .entry(x.clone())
            .or_insert(loop {
                let y = rng.gen();
                if !self.range.contains(&y) {
                    self.range.insert(y.clone());
                    break y;
                }
            })
            .clone()
    }
}

/// Ideal game for defining PRF security.
#[derive(Default)]
pub struct RandFunc<F: Func>
where
    F::Domain: Sized,
{
    table: HashMap<F::Domain, F::Range>,
}
impl<F: Func> Eval<F> for RandFunc<F>
where
    Standard: Distribution<F::Range>,
    F::Domain: Clone + std::hash::Hash + Eq,
    F::Range: Clone + std::hash::Hash + Eq,
{
    fn eval(&mut self, x: &F::Domain) -> F::Range {
        self.table
            .entry(x.clone())
            .or_insert(thread_rng().gen())
            .clone()
    }
}
\end{lstlisting}

\subsection{Traits}
\label{sec/traits}

\begin{lstlisting}
/// A generic distinguishing attacker.
pub trait Distinguisher<G> {
    fn play_then_return(&self, game: G) -> (G, bool);
    fn play(&self, game: G) -> bool {
        // Return the `bool` only.
        self.play_then_return(game).1
    }
}

/// Left-or-right encryption oracle.
pub trait LeftOrRight {
    type Plaintext;
    type Ciphertext;
    fn left_or_right(
        &self,
        m_left: &Self::Plaintext,
        m_right: &Self::Plaintext,
    ) -> Self::Ciphertext;
}

/// Oracle for obtaining the public key in a public-key cryptosystem.
pub trait GetPublicKey {
    type PublicKey;
    fn get_pk(&self) -> &Self::PublicKey;
}

/// Oracle for evaluating a keyed function.
pub trait Eval<F: Func> {
    fn eval(&mut self, x: &F::Domain) -> F::Range;
}
\end{lstlisting}

\begin{figure}
\begin{lstlisting}
/// Syntax.
pub trait SymEnc {
    type Key;
    type Plaintext;
    type Ciphertext;
    fn key_gen(&self) -> Self::Key;
    fn encrypt(&self, k: &Self::Key, m: &Self::Plaintext) -> Self::Ciphertext;
    fn decrypt(&self, k: &Self::Key, c: &Self::Ciphertext) -> Option<Self::Plaintext>;
}

/// Security.
pub struct Cpa<E: SymEnc> {
    e: E,
    k: E::Key,
    right: bool,
}
impl<E: SymEnc> Cpa<E> {
    pub fn init(e: E, right: bool) -> Self {
        let k = e.key_gen();
        Self { e, k, right }
    }
}
impl<E: SymEnc> LeftOrRight for Cpa<E> {
    type Plaintext = E::Plaintext;
    type Ciphertext = E::Ciphertext;
    fn left_or_right(&self, m_left: &E::Plaintext, m_right: &E::Plaintext) -> E::Ciphertext {
        if self.right {
            self.enc.encrypt(&self.k, m_right)
        } else {
            self.enc.encrypt(&self.k, m_left)
        }
    }
}
\end{lstlisting}
  \caption{Syntax of symmetric encryption and game $\code{Cpa}$ for defining
  security under CPA.}
  \label{fig/symenc/syntax}
  \label{fig/symenc/security}
\end{figure}




\end{document}
