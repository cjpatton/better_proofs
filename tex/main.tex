\documentclass{article}
\usepackage{amsmath, amsthm}
\usepackage{listings}
\usepackage{listings-rust}
\usepackage[margin=1in]{geometry}
\usepackage{sourcecodepro}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage[svgnames]{xcolor}

\lstset{
  language=rust,
  style=boxed,
}

% Colors

\definecolor{darkgreen}{RGB}{30,97,0}

% Theorems

\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}

% Macros

\newcommand{\authnote}[3]{%
  {
    \color{#1}%
    \textbf{[#2:~}%
    {%
      #3%
    }%
    \textbf{]}%
  }%
}
\newcommand{\cp}[1]{\authnote{darkgreen}{Chris P.}{#1}}

\newcommand{\bad}{\mathit{bad}}
\newcommand{\Adv}[1]{\textrm{\textup{Adv}}^{\textup{#1}}}
\newcommand{\Prob}[1]{\Pr\hspace{-1pt}\big[\,#1\,\big]}
\newcommand{\code}[1]{\textrm{\textup{\lstinline{#1}}}}

\title{How to write proofs for cryptographic protocols at IETF}
\author{Christopher Patton ({\texttt{\small chrispatton+ietf@gmail.com}})}

\begin{document}

\maketitle

\begin{abstract}

  The security of many protocols at IETF rests on ``pen-and-paper'' proofs that
  are difficult for humans to verify.
  %
  If the demand for provable security outpaces the capacity of human reviewers,
  then we run the risk of missing bugs in these proofs that may belie attacks.
  %
  One way to prevent this is to mechanize portions of the review process.
  %
  This essay sketches a vision for writing security proofs in which there is a
  clear division of labor between subject matter experts and experts in formal
  methods.
  %
  This, we hope, will lead to more productive interactions across disciplines
  and to more of our proofs being fully vetted.

\end{abstract}

\section{Introduction}\label{sec/intro}

This essay accompanies a talk for
\href{https://datatracker.ietf.org/group/ufmrg/about/}{UFMRG} at IETF 120.
%
It is not a traditional research paper and is based largely on my own
observations.
%
All listings in this essay can be reproduced from code in the repository
\url{https://github.com/cjpatton/better_proofs}.
%
For feedback, feel free to file an issue against the repository, or send me an
email.


\paragraph{Code-based game-playing proofs~\cite{BR06}.}
%
Game playing is a well-known paradigm for establishing computational security
properties of cryptographic protocols.
%
In this paradigm, the security goal and execution environment are modeled as a
\emph{game} played by the attacker. A \emph{proof} of security in this model
relates the attacker's advantage in winning the game to the difficulty of one
or more presumed hard problems, like cracking AES or finding short vectors on
the lattice used by the protocol.

Games are often expressed in \emph{code} rather than natural language, making
them amendable to the following proof strategy.
%
The proof consists of a sequence of games (sometimes called \emph{hybrids})
beginning with the game that defines security.
%
Each game is obtained by rewriting the code of the previous one until, in the
final game, the attacker interacts with some idealized system that it has no
hope of breaking.

The security proof establishes that, for each pair of neighboring games, the
probability of an attacker in distinguishing between them is negligible.
%
This is established in various ways:
%
sometimes a \emph{rewrite} (also called a \emph{hop} or \emph{transition})
results in a game that is semantically equivalent, in which case no attacker
can distinguish them;
%
others rewrites result in distinguishable events that occur only with small
probability, such as a collision in the range of a random oracle;
%
still others are bounded computationally, by reducing some assumed hard problem
to a distinguisher.

In recent years, security analyses of this sort have played an increasingly
central role in the design and analysis of protocols specified at IETF. We have
seen working groups move from \emph{reacting} to attacks to \emph{proactively}
ruling out (classes of) attacks during the design phase~\cite{KT16}.
%
In fact, this process has even been formalized in the TLS working
group~\cite{tls13-formal-analysis-triage-panel}.
%
While steps like these go a long way towards preventing attacks, the provable
security methodology has some well-known limitations~\cite{Ber19}.
%
We consider one of them here.

\paragraph{Our crisis of rigor.}
%
In their seminal paper on the subject from Eurocrypt 2006~\cite{BR06}, Bellare
and Rogaway assessed that many security proofs of the era were ``essentially
unverifiable''. They feared the discipline would eventually reach a ``crisis of
rigor'' in which proofs were believed without being fully vetted, allowing
errors in these proofs to go unnoticed. And some of these errors may belie
attacks. (We give some examples later in Section~\ref{sec/bugs}.)
%
%In our experience, this fear has, at least in part, come to fruition.

Today, carefully checking security proofs remains a significant challenge.
There are at least three exacerbating factors:
%
\begin{enumerate}

  \item Proofs are most often written in some \emph{pseudocode} language
    intended for human readers. These are often called \emph{pen-and-paper}
    proofs.
    %
    There is no standard pseudocode in use today, and the grammar and
    semantics of these languages are as varied as the people that use them.
    %
    Not only does this make mechanized verification nearly impossible, it also
    makes life difficult for human reviewers, many of whom have a stack of
    10 papers or more to get through, each with its own unique semantics.

  \item Protocols of interest to IETFers are becoming more complex.
    %
    First, we are seeing our community do more with cryptography, often going
    beyond well-studied goals like key exchange, authentication, and
    encryption.
    %
    Second, as attackers get more sophisticated, so must our security definitions
    capture the real execution environment in greater fidelity.
    %
    Proofs are getting \emph{longer} as a result, putting pressure on authors
    to merely ``sketch'' the proof in order to meet the page limit for the
    conference submission. Or they simply punt the proof to the paper's
    appendix, which program committee members are typically not required to
    review at all.

  \item Mechanization of security proofs can help reduce burden on human
    reviewers.
    %
    Several tools exist for this, like
    \href{https://bblanche.gitlabpages.inria.fr/CryptoVerif/}{CryptoVerif},
    \href{https://github.com/EasyCrypt/easycrypt}{EasyCrypt}, and
    \href{https://github.com/SSProve/ssprove}{SSProve}, but these tools
    are inaccessible to many folks writing pen-and-paper proofs today.
    %
    There are several reasons for this.
    %
    First and foremost, cajoling the theorem prover into generating a proof is
    a manual process that requires some degree of expertise in the theory
    underlying the tool.
    %
    These tools also require learning a new, somewhat esoteric programming
    language. They are also sometimes optimized for specific applications or
    use cases. Finally, the maturity of the software itself can make using them
    difficult.

\end{enumerate}
%
These factors put our community on a trajectory that, in my view, is not be
sustainable long term.
%
I believe we must find ways to reduce the cost of checking security proofs so
that the capacity of reviewers continues to meet the demands of those
developing cryptographic protocols for practice.

%Because each of these issues is socially constructed~\cite{Rog09} to some
%degree, we should not expect any one of them to be resolved by technical means
%alone.
%
%However, it is our belief that the current trajectory of practice-oriented
%provable security cannot be sustained indefinitely.

\paragraph{Proposal.}
%
This essay puts forward a vision for writing security proofs for cryptographic
protocols developed at IETF.
%
Our proofs ought to meet two basic requirements.
%
First, they must be immediately amendable to mechanized verification so that
human verifiers needn't check the full proof.
%
Second, generating proofs must not require significantly more effort or
expertise than pen-and-paper so that human provers are less more inclined to
give the proof in full detail rather than sketch it.

The key idea is simple: games, protocols, and proofs should all be written in a
programming language with the following properties:
%
\begin{enumerate}

  \item The language should already in wide use at IETF.

  \item The language should be high-level enough to be suitable as a
    specification language. That is is, the protocol and its intended security
    properties should be understandable without expertise in the language.

  \item The language is already used for production software. This way the
    effort spent on specifying the protocol translates more quickly into code
    that is used in practice.

\end{enumerate}
%
This is not a particularly novel idea, yet it is not an idea that has taken
root among most practitioners of provable security.
%
Part of the problem is the lack of a consensus language with suitable tools for
formal methods. As I will try to illustrate here, this situation seems to be
changing.

The potential benefit of writing game-playing proofs in an actual code rather
than pseudocode is that it creates a \emph{separation of concerns}.
%
On one end of the assembly line, the \emph{subject matter expert} specifies the
security game and protocol and generates the proof, consisting of the game
rewrites and reductions. Ideally, this requires no knowledge of formal methods.
%
On the other end of the assembly line, the \emph{formal methods expert}
verifies correctness of each of the rewrites. Ideally, this amounts to checking
equivalence of programs written in the specification language and requires only
limited knowledge of the application.

Other benefits to this approach:

\begin{itemize}
  \item Those of us IETFers who write security proofs as well as software will
    discover some surprising benefits of this approach.
    %
    For example, imagine you have written a proof in pseudocode and find you
    need to go back and tweak the definition: the process of propagating that
    tweak through the proof (in practice, a pile of hand-written \LaTeX) is
    both time-intensive and error-prone. Having a compiler with a type checker
    and a set of high-quality unit tests can make this much more sane.

  \item Cryptographers sometimes spend enormous energy working on definitions.
    Much of this time is spent probing for ``trivial'' distinguishers or
    winning conditions that suggest the attacker is too powerful or not
    captured in the right way.
    %
    Writing such definitions in code might make it possible to formalize such
    conditions symbolically in tools like
    \href{https://tamarin-prover.com/}{Tamarin} or
    \href{https://bblanche.gitlabpages.inria.fr/proverif/}{ProVerif}.
\end{itemize}

Note that this proposal is grounded in extensive experience writing
pen-and-paper proofs (sometimes with bugs!), but no professional experience
with mechanized verification or other formal methods.
%
It may be that I've massively underestimated how much work is being delegated
to formal methods.

\paragraph{Outline.}
%
By way of illustrating this proposal, this essay presents a few elementary
examples of security proofs from the cryptographic literature, transcribing
them into a high-level programming language.
%
These examples illustrate the kind of work carried out by the \emph{subject
matter expert}; the task of the \emph{formal methods expert} is to prove each
claim (written as ``\textbf{Claim}'') in the body of the proof.

Section~\ref{sec/hybrid} recalls the simple hybrid, public-key encryption
scheme from Mike Rosulek's ``Joy of Cryptography''~\cite{joy} and its proof of
security under chosen plaintext attack.
%
Section~\ref{sec/switching} considers the PRP/PRF switching lemma, a bit of
folklore that is well-known among cryptographers.
%
These examples illustrate three common game rewrites:
%
\emph{equivalent-rewrite}, in which the new code is semantically equivalent
(useful for setting up the next step in the proof);
%
\emph{equivalent-by-reduction}, in which an assumed hard problem is reduced to
a distinguisher between the games; and
%
\emph{equivalent-until-bad}, in which the new game is equivalent up to some
distinguishing, ``bad'' event~\cite{BR06}.

We begin in Section~\ref{sec/bugs} with a brief (and incomplete) overview of
some documented cases of bugs in security proofs.
%
We then describe our notation and conventions (Section~\ref{sec/notation})
before diving into examples.

\paragraph{What about UC?}
%
While we focus on game-playing proofs in this essay, the same proposal can be
applied to what is often called the \emph{simulation paradigm}. Here security
is defined relative to some \emph{ideal functionality}, and we say the protocol
\emph{realizes} that ideal functionality if, for every attacker, there exists a
simulator such that the adversary's interaction with the real system is
indistinguishable from the simulator's interaction with the ideal
functionality.

There is no fundamental difference between simulation- and game-based
definitions that makes mechanization of proofs in one paradigm harder than the
other.
%
However, the details of popular simulation frameworks, like the UC
framework~\cite{Can01}, can be rather involved, making mechanized proofs more
difficult~\cite{CSV19}.
%
Games are an attractive target merely because the details of the model are
explicit.

\section{Bugs in Security Proofs}\label{sec/bugs}

\paragraph{OCB2.}
%
OCB2 (``Offset Code Book'') is a symmetric, authenticated encryption scheme
standardized by ISO in 2009 (ISO/IEC 19772:2009). In 2018~\cite{IIMP19}, an
existential forgery attack against OCB2 was demonstrated that exploited a detail
of the construction that was overlooked in the original security analysis.
%
The attack is simple and efficient and, with a bit of work, can be improved
into a total break of both authenticity and confidentiality.
%
Note that its successor, OCB3 (RFC 7253), is not vulnerable to the same class
of attacks.

\paragraph{GCM.}
%
GCM (``Galois Counter Mode'') is a symmetric, authenticated encryption scheme
that has been recommended by NIST since 2007 and is widely used at IETF and
beyond.
%
In 2012~\cite{IOM12}, an efficient distinguisher was discovered that
contradicts the concrete security claimed by the existing security proof.
%
The attack does not result in a total break. In fact, the authors describe an
alternative proof with slightly looser security.
%
It does, however, impact the safety limits for GCM~\cite{irtf-cfrg-aead-limits-08}.

\paragraph{HMQV.}
%
The HMQV protocol is a well-known milestone in the evolution of authenticated
key exchange, being one of the earliest such protocols with a provable security
treatment.
%
It is based on the MQV family of protocols (``Hashed MQV''), some of which
appeared in various standards in the 1990s.
%
Shortly after the proof was published at Crypto 2005~\cite{Kra05}, the protocol
was (somewhat famously) broken the same year~\cite{Men05}.
%
The attacks exploit HMQV's omission of public-key validation, pointing to at
least one flaw in the security proof where a public-key controlled by the
attacker was assumed to be valid. (See the preface of~\cite{Kra05}.)

\paragraph{OAEP.}
%
OAEP (``Optimzed Assymetric Encryption Padding'') is a transformation of a
trapdoor permutation into a public-key encryption scheme. The instantiation
most widely used today, RSA-OAEP, was standardized in 1998 (RFC 2437).
%
The original security proof (Eurocrypt 1994) was later shown by Victor Shoup to
be flawed~\cite{Sho01}. Shoup goes a bit further, proving there is \emph{no}
black-box reduction from the trapdoor permutation to the security of OAEP.
%
However, the paper also shows that the flaw does not translate into an attack
on RSA-OAEP in particular. Interestingly, the corrected proof no longer applies
to any trapdoor permutation, but exploits algebraic properties of RSA.

\paragraph{The author's own work.}
%
A paper by the author tries to formalize conditions under which key reuse
across different protocols is safe~\cite{PS19}. (For example, consider the
problem of securely using an already deployed ECDSA secret key as a static
Diffie-Hellman key in another protocol.)
%
The main ``result'' of this paper gives a sufficient condition under which
security of a given application is maintained in the presence of key reuse.
%
The published version (Crypto 2019) contains a flaw related to the
programmability of the random oracle by the simulator.
%
This was discovered by an anonymous reviewer of a follow-up paper (Crypto
2020~\cite{PS20}) in a more general context.
%
Additional issues were pointed out a few years later, but the paper~\cite{PS19}
has not yet been updated to address them. (This is work in progress!)


\section{Notation}\label{sec/notation}

All algorithms, including games and adversaries, are Rust
(\url{https://www.rust-lang.org/}) programs without asynchronous semantics
(i.e., with the $\code{async}$ and $\code{await}$ key words
removed).\footnote{Asynchronous Rust is excluded because it is not needed to
formalize execution of games.}
%
By convention, an adversary's runtime includes the time it takes to initialize
its game and evaluate its oracle queries.
%
Let $\code{block}$ be a Rust code block whose last statement is an expression
that evaluates to $\code{bool}$.
%
We denote by $\Prob{\code{block}}$ the probability that execution of
$\code{block}$ halts (without panicking) and outputs $\code{true}$.
%
We model
\href{https://rust-random.github.io/rand/rand/fn.thread_rng.html}{$\code{thread_rng()}$}
from the
\href{https://rust-random.github.io/rand/rand/index.html}{$\code{rand}$} crate
as an ideal source of uniform random coins.

\paragraph{Why Rust?}
%
Rust easily meets two of our criteria from Section~\ref{sec/intro}: it is
widely used at IETF and in production software systems.
%
Whether it is suitable as a specification language is debatable; I will try to
make the case that it is, by conveying to the reader what elements of Rust are
important to understanding definitions herein.

Another important reason for choosing Rust is that it is the specification
language of the HAX toolchain (\url{https://cryspen.com/hax/}).
%
HAX is used to transcribe Rust into one of many \emph{backend} languages, such
as F* and Coq, where existing tools can be applied for various purposes.
%
While HAX was not designed with this particular use case in mind, we expect it
to amendable to our purposes, perhaps with some changes to the tool.


\section{Example: Hybrid Encryption}\label{sec/hybrid}

We first consider the hybrid public-key encryption (PKE) scheme of
\cite[Chapter~15]{joy}.
%
The proof demonstrates two types of game transitions: \emph{equivalent-rewrite}
and \emph{equivalent-by-reduction}.


\begin{figure}[t]
\begin{lstlisting}
/// Syntax.
pub trait PubEnc {
    type PublicKey;
    type SecretKey;
    type Plaintext;
    type Ciphertext;
    fn key_gen(&self) -> (Self::PublicKey, Self::SecretKey);
    fn encrypt(&self, pk: &Self::PublicKey, m: &Self::Plaintext) -> Self::Ciphertext;
    fn decrypt(&self, sk: &Self::SecretKey, c: &Self::Ciphertext) -> Option<Self::Plaintext>;
}

/// Security.
pub struct PubCpa<E: PubEnc> {
    enc: E,
    pk: E::PublicKey,
    right: bool,
}
impl<E: PubEnc> PubCpa<E> {
    pub fn init(enc: E, right: bool) -> Self {
        let (pk, _sk) = e.key_gen();
        Self { enc, pk, right }
    }
}
impl<E: PubEnc> GetPublicKey for PubCpa<E> {
    type PublicKey = E::PublicKey;
    fn get_pk(&self) -> &E::PublicKey {
        &self.pk
    }
}
impl<E: SymEnc> LeftOrRight for PubCpa<E> {
    type Plaintext = E::Plaintext;
    type Ciphertext = E::Ciphertext;
    fn left_or_right(&self, m_left: &E::Plaintext, m_right: &E::Plaintext) -> E::Ciphertext {
        if self.right {
            self.enc.encrypt(&self.k, m_right)
        } else {
            self.enc.encrypt(&self.k, m_left)
        }
    }
}
\end{lstlisting}
  \caption{Syntax of PKE and game \lstinline{PubCpa}
  for defining security under chosen plaintext attack (CPA).}
  \label{fig/pubenc/security}
  \label{fig/pubenc/syntax}
\end{figure}


\paragraph{Syntax.}
%
A PKE scheme implements the $\code{PubEnc}$ trait listed in
Figure~\ref{fig/pubenc/syntax}.
%
(A \emph{trait} is similar to an interface or abstract base class in other
languages that defines an API but not an implementation of the API.)
%
Let $\code{enc: E}$ implement $\code{PubEnc}$.
%
(That is, $\code{enc}$ is a PKE scheme because its type, denoted $\code{E}$
implements the $\code{PubEnc}$ trait. See Figure~\ref{fig/hybrid}, line~5.)
%
We say $\code{enc}$ is \emph{correct} if for all $\code{m} \in
\code{E::Plaintext}$ it holds that
%
\[
  \Prob{
    \code{let (pk, sk) = enc.key_gen();
    enc.decrypt(sk, enc.encrypt(pk, m)) == Some(m)}
  } = 1 \,.
\]


\paragraph{Security.}
%
Security under chosen plaintext attack (CPA) is defined by the $\code{PubCpa}$
game in Figure~\ref{fig/pubenc/security}.
%
It captures a left-or-right notion of indistinguishability by giving the
attacker an oracle \hyperref[sec/traits]{$\code{LeftOrRight}$} that encrypts
one of two messages chosen by the attacker and returns the ciphertext.
%
(Each trait implemented by the game defines an oracle that the attacker has
access to. One is $\code{LeftOrRight}$; the other is
\hyperref[sec/traits]{$\code{GetPublicKey}$}, which grants access to the
encryption key.)
%
Which message is encrypted is controlled by a boolean $\code{right}$ used to
initialize the game (line 19).

\begin{definition}[{\cite[Definition 15.1]{joy}}]
  Let~$A$ implement \hyperref[sec/traits]{$\code{Distinguisher}$}.
  %
  Let~$\code{enc}$ implement \hyperref[fig/pubenc/syntax]{$\code{PubEnc}$}.
  %
  Define the advantage of attacker~$A$ in breaking the security of
  $\code{enc}$ under CPA as
  %
  \[
    \Adv{cpa}_{\code{enc}}(A) =
      \Prob{A\code{.play(PubCpa::init(enc, false))}} -
      \Prob{A\code{.play(PubCpa::init(enc, true))}} \,,
  \]
  %
  where $\code{PubCpa}$ is as defined in Figure~\ref{fig/pubenc/security}.
  %
  Informally, we say $\code{enc}$ is secure under CPA if every efficient
  attacker has small advantage.
\end{definition}

\begin{remark}
  This definition implicitly requires length hiding, since there is no
  requirement that the challenge plaintext $\code{m_left}$ and $\code{m_right}$
  have the same length. For most PKE schemes, the length of the ciphertext is a
  function of the length of the plaintext.
\end{remark}


\begin{figure}[t]
\begin{lstlisting}
pub struct Hybrid<P, S> {
    pub pub_enc: P,
    pub sym_enc: S,
}
impl<P, S> PubEnc for Hybrid<P, S>
where
    S: SymEnc,
    P: PubEnc<Plaintext = S::Key>,
    Standard: Distribution<S::Key>,
{
    type PublicKey = P::PublicKey;
    type SecretKey = P::SecretKey;
    type Plaintext = S::Plaintext;
    type Ciphertext = (P::Ciphertext, S::Ciphertext);
    fn key_gen(&self) -> (P::PublicKey, P::SecretKey) {
        self.pub_enc.key_gen()
    }
    fn encrypt(&self, pk: &P::PublicKey, m: &S::Plaintext) -> (P::Ciphertext, S::Ciphertext) {
        let tk = thread_rng().gen(); // "temporary key"
        let c_pub = self.pub_enc.encrypt(pk, &tk);
        let c_sym = self.sym_enc.encrypt(&tk, m);
        (c_pub, c_sym)
    }
    fn decrypt(
        &self,
        sk: &Self::SecretKey,
        (c_pub, c_sym): &(P::Ciphertext, S::Ciphertext),
    ) -> Option<Self::Plaintext> {
        let tk = self.pub_enc.decrypt(sk, c_pub)?;
        let m = self.sym_enc.decrypt(&tk, c_sym)?;
        Some(m)
    }
}
\end{lstlisting}
  \caption{Hybrid PKE scheme of \cite[Construction 15.8]{joy}.}
  \label{fig/hybrid}
\end{figure}


\paragraph{Construction.}
%
In practice, PKE schemes are most often constructed by combining symmetric
encryption with a mechanism for encapsulating the encryption key to the
intended recipient~\cite{rfc9180} (that is, the holder of the secret key
corresponding to the public encapsulation key).
%
By way of gentle introduction to this paradigm, Mike Rosulek gives a
construction of CPA-secure, hybrid encryption in ``The Joy of
Cryptography''~\cite{joy}.
%
We recall this construction in Figure~\ref{fig/hybrid}.

This construction transforms a symmetric encryption scheme $\code{sym_enc: S}$
into a PKE scheme.
%
The syntax and security of symmetric encryption are defined similarly to PKE,
except there is no public key; we defer the formal definition to
Appendix~\ref{sec/symenc}.
%
The transformation involves a PKE scheme $\code{pub_enc: E}$ with a small
plaintext space. In particular, we require that plaintext space of
$\code{pub_enc}$ is the same as the key space for $\code{sym_enc}$. This is
formalized by the trait bound $\code{E: PubEnc<Plaintext = S::Key>}$ (see line
8).

To encrypt a plaintext, we choose a ``temporary key'' $\code{tk}$ uniform
randomly from the key space of $\code{sym_enc}$.
%
We then encrypt $\code{tk}$ using the PKE scheme $\code{pub_enc}$.
%
Finally, we encrypt the plaintext under $\code{tk}$ and output both
ciphertexts.

\begin{theorem}[{\cite[Claim~15.9]{joy}}]\label{thm/hybrid}
  Suppose that $\code{pub_enc}$ and $\code{sym_enc}$ satisfy the constraints of
  Figure~\ref{fig/hybrid} and let $\code{hybrid} = \code{Hybrid\{
    pub_enc, sym_enc \}}$.
  %
  Then for every $\code{hybrid}$-attacker $A$ there exist a
  $\code{sym_enc}$-attacker $B$ and a $\code{pub_enc}$-attacker $C$ with
  the same runtime as $A$ for which
  %
  \[
    \Adv{cpa}_\code{hybrid}(A) \leq
      \Adv{cpa}_\code{sym_enc}(B) +
      2\cdot\Adv{cpa}_\code{pub_enc}(C) \,.
  \]
\end{theorem}

\begin{proof}
  \input{hybrid-proof}
\end{proof}


\section{Example: The PRP/PRF Switching Lemma}\label{sec/switching}

In this section we fix the PRP/PRF switching lemma~\cite{BR06}, which states
that a good pseudorandom permutation (PRP) is a good pseudorandom function
(PRF) up to birthday attacks.
%
The proof demonstrates the \emph{equivalent-until-bad} transition.

\begin{figure}[t]
\begin{lstlisting}
/// Syntax.
pub trait Func {
    type Key;
    type Domain: ?Sized;
    type Range;
    fn eval(&self, k: &Self::Key, x: &Self::Domain) -> Self::Range;
}

/// Real game for defining PRP and PRF security.
pub struct Real<F: Func> {
    f: F,
    k: F::Key,
}
impl<F: Func> Real<F>
where
    Standard: Distribution<F::Key>,
{
    pub fn with(f: F) -> Self {
        let k = thread_rng().gen();
        Self { f, k }
    }
}
impl<F: Func> Eval<F> for Real<F> {
    fn eval(&mut self, x: &F::Domain) -> F::Range {
        self.f.eval(&self.k, x)
    }
}
\end{lstlisting}
  \caption{Syntax and real security game for PRPs and PRFs. The ideal games are
  listed in Appendix~\ref{sec/func/ideal}.}
  \label{fig/func/syntax}
  \label{fig/func/real}
\end{figure}


Syntactically, both a PRP and PRF implement the $\code{Eval}$ trait listed in
Figure~\ref{fig/func/syntax}.\footnote{A PRP also implements the inverse of
$\code{Eval::eval()}$. We do not list this syntax because it is not needed
here.}
%
For example, the AES-128 blockipher would set $\code{Key}$, $\code{Domain}$,
and $\code{Range}$ to $\code{[u8; 16]}$.
%
Security is defined by the $\code{Real}$ game in Figure~\ref{fig/func/real},
which gives the attacker an oracle for the function with a randomly sampled
key. In the ideal PRP and PRF games, the oracle lazy evaluates, respectively, a
random permutation and a random function.
%
The ideal games, denoted $\code{RandPerm}$ and $\code{RandFunc}$, are listed
for completeness in Appendix~\ref{sec/func/ideal}.

Let $\code{f: F}$ implement \hyperref[fig/func/syntax]{$\code{Func}$} and
let~$A$ implement \hyperref[sec/traits]{$\code{Distinguisher}$} for
\hyperref[sec/traits]{$\code{Eval<F>}$}.

\begin{definition}[PRP]
  Define the advantage of~$A$ in distinguishing $\code{f}$ from a random
  permutation as
  %
  \[
    \Adv{prp}_\code{f}(A) =
      \Prob{A\code{.play(Real::with(f))}} -
      \Prob{A\code{.play(RandPerm::default())}} \,.
  \]
  %
  (The $\code{default()}$ method is provided by the
  \href{https://doc.rust-lang.org/std/default/trait.Default.html}{$\code{Default}$}
  trait, which the \hyperref[sec/traits]{$\code{RandPerm}$} trait derives automatically.
  The hash map and hash set are initially empty.)
  %
  Informally, we say $\code{f}$ is a PRP if every efficient attacker gets small
  advantage.
\end{definition}

\begin{definition}[PRF]
  Define the advantage of~$A$ in distinguishing $\code{f}$ from a random
  function as
  %
  \[
    \Adv{prf}_\code{f}(A) =
      \Prob{A\code{.play(Real::with(f))}} -
      \Prob{A\code{.play(RandFunc::default())}} \,.
  \]
  %
  Informally, we say $\code{f}$ is a PRF if every efficient attacker gets small
  advantage.
\end{definition}

\begin{lemma}[{\cite[Lemma 1]{BR06}}]
  Suppose $A$ makes at most $q$ queries to its oracle. Then
  %
  \[
    \Adv{prp}_\code{f}(A) \leq
      \Adv{prf}_\code{f}(A) +
      \frac{q(q-1)}{2|\code{F::Range}|} \,.
  \]
\end{lemma}
\begin{proof}
  \input{switching-proof}
\end{proof}


\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{references}


\appendix


\section{Deferred Definitions}

\begin{figure}[t]
\begin{lstlisting}
/// Syntax.
pub trait SymEnc {
    type Key;
    type Plaintext;
    type Ciphertext;
    fn key_gen(&self) -> Self::Key;
    fn encrypt(&self, k: &Self::Key, m: &Self::Plaintext) -> Self::Ciphertext;
    fn decrypt(&self, k: &Self::Key, c: &Self::Ciphertext) -> Option<Self::Plaintext>;
}

/// Security.
pub struct Cpa<E: SymEnc> {
    e: E,
    k: E::Key,
    right: bool,
}
impl<E: SymEnc> Cpa<E> {
    pub fn init(e: E, right: bool) -> Self {
        let k = e.key_gen();
        Self { e, k, right }
    }
}
impl<E: SymEnc> LeftOrRight for Cpa<E> {
    type Plaintext = E::Plaintext;
    type Ciphertext = E::Ciphertext;
    fn left_or_right(&self, m_left: &E::Plaintext, m_right: &E::Plaintext) -> E::Ciphertext {
        if self.right {
            self.enc.encrypt(&self.k, m_right)
        } else {
            self.enc.encrypt(&self.k, m_left)
        }
    }
}
\end{lstlisting}
  \caption{Syntax of symmetric encryption and game $\code{Cpa}$ for defining
  security under CPA.}
  \label{fig/symenc/syntax}
  \label{fig/symenc/security}
\end{figure}



\subsection{Symmetric Encryption}
\label{sec/symenc}

A symmetric encryption scheme implements the $\code{SymEnc}$ trait listed in
Figure~\ref{fig/symenc/syntax}.
%
Let $\code{enc: E}$ implement $\code{SymEnc}$.
%
We say $\code{enc}$ is \emph{correct} if for all $\code{m} \in
\code{E::Plaintext}$ it holds that
%
\[
  \Prob{
    \code{let k = e.key_gen();
    enc.decrypt(k, enc.encrypt(k, m)) == Some(m)}
  } = 1 \,.
\]
%
Security under chosen plaintext attack (CPA) is defined by the $\code{Cpa}$
game in Figure~\ref{fig/symenc/security}.

\begin{definition}[{\cite[Definition 7.1]{joy}}]
  Let $A$ implement \hyperref[sec/traits]{$\code{Distinguisher}$}.
  %
  Let~$\code{enc}$ implement \hyperref[fig/symenc/syntax]{$\code{SymEnc}$}.
  %
  Define the advantage of~$A$ in breaking the security of $\code{enc}$ under CPA
  as
  %
  \[
    \Adv{cpa}_{\code{enc}}(A) =
      \Prob{A\code{.play(Cpa::init(enc, false))}} -
      \Prob{A\code{.play(Cpa::init(enc, true))}} \,.
  \]
  %
  Informally, we say $\code{enc}$ is secure under CPA if every efficient adversary
  has small advantage.
\end{definition}


\subsection{Ideal games for defining PRPs and PRFs}
\label{sec/func/ideal}

\begin{lstlisting}
/// Ideal game for defining PRP security.
#[derive(Default)]
pub struct RandPerm<F: Func>
where
    F::Domain: Sized,
{
    table: HashMap<F::Domain, F::Range>,
    range: HashSet<F::Range>,
}
impl<F: Func> Eval<F> for RandPerm<F>
where
    Standard: Distribution<F::Range>,
    F::Domain: Clone + std::hash::Hash + Eq,
    F::Range: Clone + std::hash::Hash + Eq,
{
    fn eval(&mut self, x: &F::Domain) -> F::Range {
        let mut rng = thread_rng();
        self.table
            .entry(x.clone())
            .or_insert(loop {
                let y = rng.gen();
                if !self.range.contains(&y) {
                    self.range.insert(y.clone());
                    break y;
                }
            })
            .clone()
    }
}

/// Ideal game for defining PRF security.
#[derive(Default)]
pub struct RandFunc<F: Func>
where
    F::Domain: Sized,
{
    table: HashMap<F::Domain, F::Range>,
}
impl<F: Func> Eval<F> for RandFunc<F>
where
    Standard: Distribution<F::Range>,
    F::Domain: Clone + std::hash::Hash + Eq,
    F::Range: Clone + std::hash::Hash + Eq,
{
    fn eval(&mut self, x: &F::Domain) -> F::Range {
        self.table
            .entry(x.clone())
            .or_insert(thread_rng().gen())
            .clone()
    }
}
\end{lstlisting}

\subsection{Traits}
\label{sec/traits}

\begin{lstlisting}
/// A generic distinguishing attacker.
pub trait Distinguisher<G> {
    fn play_then_return(&self, game: G) -> (G, bool);
    fn play(&self, game: G) -> bool {
        // Return the `bool` only.
        self.play_then_return(game).1
    }
}

/// Left-or-right encryption oracle.
pub trait LeftOrRight {
    type Plaintext;
    type Ciphertext;
    fn left_or_right(
        &self,
        m_left: &Self::Plaintext,
        m_right: &Self::Plaintext,
    ) -> Self::Ciphertext;
}

/// Oracle for obtaining the public key in a public-key cryptosystem.
pub trait GetPublicKey {
    type PublicKey;
    fn get_pk(&self) -> &Self::PublicKey;
}

/// Oracle for evaluating a keyed function.
pub trait Eval<F: Func> {
    fn eval(&mut self, x: &F::Domain) -> F::Range;
}
\end{lstlisting}

\end{document}
